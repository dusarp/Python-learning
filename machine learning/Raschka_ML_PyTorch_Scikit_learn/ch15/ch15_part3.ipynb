{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Length: 1112350\n",
      "Unique Characters: 80\n"
     ]
    }
   ],
   "source": [
    "#loads the Verne's MThe Mysterious Island\n",
    "import numpy as np\n",
    "\n",
    "## Reading and processing text\n",
    "with open('1268-0.txt', 'r', encoding=\"utf8\") as fp:\n",
    "    text=fp.read()\n",
    "    \n",
    "start_indx = text.find('THE MYSTERIOUS ISLAND')\n",
    "end_indx = text.find('End of the Project Gutenberg')\n",
    "\n",
    "text = text[start_indx:end_indx]\n",
    "char_set = set(text)\n",
    "print('Total Length:', len(text))\n",
    "print('Unique Characters:', len(char_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text encoded shape:  (1112350,)\n",
      "THE MYSTERIOUS       == Encoding ==>  [44 32 29  1 37 48 43 44 29 42 33 39 45 43  1]\n",
      "[33 43 36 25 38 28]  == Reverse  ==>  ISLAND\n"
     ]
    }
   ],
   "source": [
    "#building a dictionary for mapping characters to integers\n",
    "chars_sorted = sorted(char_set)\n",
    "char2int = {ch:i for i,ch in enumerate(chars_sorted)}\n",
    "char_array = np.array(chars_sorted)\n",
    "\n",
    "text_encoded = np.array(\n",
    "    [char2int[ch] for ch in text],\n",
    "    dtype=np.int32)\n",
    "\n",
    "print('Text encoded shape: ', text_encoded.shape)\n",
    "\n",
    "print(text[:15], '     == Encoding ==> ', text_encoded[:15])\n",
    "print(text_encoded[15:21], ' == Reverse  ==> ', ''.join(char_array[text_encoded[15:21]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mindet beolvasta, el birok vele kezdeni cuccolni\n"
     ]
    }
   ],
   "source": [
    "#cuccok\n",
    "#import torch\n",
    "#from torch.utils.data import DataLoader\n",
    "#import torch.nn as nn\n",
    "#from torch.distributions.categorical import Categorical\n",
    "print(\"Mindet beolvasta, el birok vele kezdeni cuccolni\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44 -> T\n",
      "32 -> H\n",
      "29 -> E\n",
      "1 ->  \n",
      "37 -> M\n"
     ]
    }
   ],
   "source": [
    "#print out the first five\n",
    "for ex in text_encoded[:5]:\n",
    "    print('{} -> {}'.format(ex, char_array[ex]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44 -> T\n",
      "32 -> H\n",
      "29 -> E\n",
      "1 ->  \n",
      "37 -> M\n",
      "48 -> Y\n",
      "43 -> S\n",
      "44 -> T\n",
      "29 -> E\n",
      "42 -> R\n",
      "33 -> I\n",
      "39 -> O\n",
      "45 -> U\n",
      "43 -> S\n",
      "1 ->  \n",
      "33 -> I\n",
      "43 -> S\n",
      "36 -> L\n",
      "25 -> A\n",
      "38 -> N\n",
      "28 -> D\n",
      "1 ->  \n",
      "6 -> *\n",
      "6 -> *\n",
      "6 -> *\n",
      "0 -> \n",
      "\n",
      "0 -> \n",
      "\n",
      "0 -> \n",
      "\n",
      "0 -> \n",
      "\n",
      "0 -> \n",
      "\n",
      "40 -> P\n",
      "67 -> r\n",
      "64 -> o\n",
      "53 -> d\n",
      "70 -> u\n",
      "52 -> c\n",
      "54 -> e\n",
      "53 -> d\n",
      "1 ->  \n",
      "51 -> b\n",
      "74 -> y\n",
      "1 ->  \n",
      "25 -> A\n",
      "63 -> n\n",
      "69 -> t\n",
      "57 -> h\n",
      "64 -> o\n",
      "63 -> n\n",
      "74 -> y\n",
      "1 ->  \n",
      "37 -> M\n",
      "50 -> a\n",
      "69 -> t\n",
      "64 -> o\n",
      "63 -> n\n",
      "50 -> a\n",
      "60 -> k\n",
      "7 -> ,\n",
      "1 ->  \n",
      "50 -> a\n",
      "63 -> n\n",
      "53 -> d\n",
      "1 ->  \n",
      "44 -> T\n",
      "67 -> r\n",
      "54 -> e\n",
      "71 -> v\n",
      "64 -> o\n",
      "67 -> r\n",
      "1 ->  \n",
      "27 -> C\n",
      "50 -> a\n",
      "67 -> r\n",
      "61 -> l\n",
      "68 -> s\n",
      "64 -> o\n",
      "63 -> n\n",
      "0 -> \n",
      "\n",
      "0 -> \n",
      "\n",
      "0 -> \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#all the 80?\n",
    "for ex in text_encoded[:80]:\n",
    "    print('{} -> {}'.format(ex, char_array[ex]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[44 32 29  1 37 48 43 44 29 42 33 39 45 43  1 33 43 36 25 38 28  1  6  6\n",
      "  6  0  0  0  0  0 40 67 64 53 70 52 54 53  1 51]  ->  74\n",
      "'THE MYSTERIOUS ISLAND ***\\n\\n\\n\\n\\nProduced b'  ->  'y'\n"
     ]
    }
   ],
   "source": [
    "seq_length = 40\n",
    "chunk_size = seq_length + 1\n",
    "\n",
    "text_chunks = [text_encoded[i:i+chunk_size] \n",
    "               for i in range(len(text_encoded)-chunk_size+1)] \n",
    "\n",
    "## inspection:\n",
    "for seq in text_chunks[:1]:\n",
    "    input_seq = seq[:seq_length]\n",
    "    target = seq[seq_length] \n",
    "    print(input_seq, ' -> ', target)\n",
    "    print(repr(''.join(char_array[input_seq])), \n",
    "          ' -> ', repr(''.join(char_array[target])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6866/2527503007.py:15: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /croot/pytorch_1681837265408/work/torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  seq_dataset = TextDataset(torch.tensor(text_chunks))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, text_chunks):\n",
    "        self.text_chunks = text_chunks\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text_chunks)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text_chunk = self.text_chunks[idx]\n",
    "        return text_chunk[:-1].long(), text_chunk[1:].long()\n",
    "    \n",
    "seq_dataset = TextDataset(torch.tensor(text_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Input (x): 'THE MYSTERIOUS ISLAND ***\\n\\n\\n\\n\\nProduced b'\n",
      "Target (y): 'HE MYSTERIOUS ISLAND ***\\n\\n\\n\\n\\nProduced by'\n",
      "\n",
      " Input (x): 'HE MYSTERIOUS ISLAND ***\\n\\n\\n\\n\\nProduced by'\n",
      "Target (y): 'E MYSTERIOUS ISLAND ***\\n\\n\\n\\n\\nProduced by '\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, (seq, target) in enumerate(seq_dataset):\n",
    "    print(' Input (x):', repr(''.join(char_array[seq])))\n",
    "    print('Target (y):', repr(''.join(char_array[target])))\n",
    "    print()\n",
    "    if i == 1:\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cuda available check\n",
    "if torch.cuda.is_available():\n",
    "  device = torch.device(\"cuda:0\")\n",
    "else:\n",
    "  device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    " \n",
    "batch_size = 64\n",
    "\n",
    "torch.manual_seed(1)\n",
    "seq_dl = DataLoader(seq_dataset, batch_size=batch_size, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (embedding): Embedding(80, 256)\n",
       "  (rnn): LSTM(256, 512, batch_first=True)\n",
       "  (fc): Linear(in_features=512, out_features=80, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, rnn_hidden_size):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim) \n",
    "        self.rnn_hidden_size = rnn_hidden_size\n",
    "        self.rnn = nn.LSTM(embed_dim, rnn_hidden_size, \n",
    "                           batch_first=True)\n",
    "        self.fc = nn.Linear(rnn_hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, x, hidden, cell):\n",
    "        out = self.embedding(x).unsqueeze(1)\n",
    "        out, (hidden, cell) = self.rnn(out, (hidden, cell))\n",
    "        out = self.fc(out).reshape(out.size(0), -1)\n",
    "        return out, hidden, cell\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        hidden = torch.zeros(1, batch_size, self.rnn_hidden_size)\n",
    "        cell = torch.zeros(1, batch_size, self.rnn_hidden_size)\n",
    "        return hidden.to(device), cell.to(device)\n",
    "    \n",
    "vocab_size = len(char_array)\n",
    "embed_dim = 256\n",
    "rnn_hidden_size = 512\n",
    "\n",
    "torch.manual_seed(1)\n",
    "model = RNN(vocab_size, embed_dim, rnn_hidden_size) \n",
    "model = model.to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss: 4.3722\n",
      "Epoch 500 loss: 1.3963\n",
      "Epoch 1000 loss: 1.3481\n",
      "Epoch 1500 loss: 1.2228\n",
      "Epoch 2000 loss: 1.2297\n",
      "Epoch 2500 loss: 1.2125\n",
      "Epoch 3000 loss: 1.1546\n",
      "Epoch 3500 loss: 1.1538\n",
      "Epoch 4000 loss: 1.2010\n",
      "Epoch 4500 loss: 1.1540\n",
      "Epoch 5000 loss: 1.0927\n",
      "Epoch 5500 loss: 1.1271\n",
      "Epoch 6000 loss: 1.1377\n",
      "Epoch 6500 loss: 1.1313\n",
      "Epoch 7000 loss: 1.1064\n",
      "Epoch 7500 loss: 1.1777\n",
      "Epoch 8000 loss: 1.1365\n",
      "Epoch 8500 loss: 1.1645\n",
      "Epoch 9000 loss: 1.1281\n",
      "Epoch 9500 loss: 1.1107\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "\n",
    "num_epochs = 10000 \n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    hidden, cell = model.init_hidden(batch_size)\n",
    "    seq_batch, target_batch = next(iter(seq_dl))\n",
    "    seq_batch = seq_batch.to(device)\n",
    "    target_batch = target_batch.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    loss = 0\n",
    "    for c in range(seq_length):\n",
    "        pred, hidden, cell = model(seq_batch[:, c], hidden, cell) \n",
    "        loss += loss_fn(pred, target_batch[:, c])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    loss = loss.item()/seq_length\n",
    "    if epoch % 500 == 0:\n",
    "        print(f'Epoch {epoch} loss: {loss:.4f}')\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities: [0.33333334 0.33333334 0.33333334]\n",
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [2]\n",
      " [1]\n",
      " [1]]\n"
     ]
    }
   ],
   "source": [
    "#evaluation: generating a new text passage\n",
    "from torch.distributions.categorical import Categorical\n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "logits = torch.tensor([[1.0, 1.0, 1.0]])\n",
    "\n",
    "print('Probabilities:', nn.functional.softmax(logits, dim=1).numpy()[0])\n",
    "\n",
    "m = Categorical(logits=logits)\n",
    "samples = m.sample((10,))\n",
    " \n",
    "print(samples.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "\n",
    "logits = torch.tensor([[1.0, 1.0, 3.0]])\n",
    "\n",
    "print('Probabilities:', nn.functional.softmax(logits, dim=1).numpy()[0])\n",
    "\n",
    "m = Categorical(logits=logits)\n",
    "samples = m.sample((10,))\n",
    " \n",
    "print(samples.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The island containing the photoys, and in this height. He knew therefore discovered it.\n",
      "\n",
      "“Although!”, he into which sourses between the cocks.”\n",
      "\n",
      "some day, and though he had paped Jup had lost the cold becatively by diminous place, and how doubles, and it was evident to attempt the\n",
      "reporter and his coming was surelett, just afterwards the 30th of the lake. It were hidderness, and if the\n",
      "eal of its countenanches, only by a lighted lightening, and dragged\n",
      "he he madely received.\n",
      "\n",
      "“Yes, to return performed! Sp\n"
     ]
    }
   ],
   "source": [
    "def sample(model, starting_str, \n",
    "           len_generated_text=500, \n",
    "           scale_factor=1.0):\n",
    "\n",
    "    encoded_input = torch.tensor([char2int[s] for s in starting_str])\n",
    "    encoded_input = torch.reshape(encoded_input, (1, -1))\n",
    "\n",
    "    generated_str = starting_str\n",
    "\n",
    "    model.eval()\n",
    "    hidden, cell = model.init_hidden(1)\n",
    "    hidden = hidden.to('cpu')\n",
    "    cell = cell.to('cpu')\n",
    "    for c in range(len(starting_str)-1):\n",
    "        _, hidden, cell = model(encoded_input[:, c].view(1), hidden, cell) \n",
    "    \n",
    "    last_char = encoded_input[:, -1]\n",
    "    for i in range(len_generated_text):\n",
    "        logits, hidden, cell = model(last_char.view(1), hidden, cell) \n",
    "        logits = torch.squeeze(logits, 0)\n",
    "        scaled_logits = logits * scale_factor\n",
    "        m = Categorical(logits=scaled_logits)\n",
    "        last_char = m.sample()\n",
    "        generated_str += str(char_array[last_char])\n",
    "        \n",
    "    return generated_str\n",
    "\n",
    "torch.manual_seed(1)\n",
    "model.to('cpu')\n",
    "print(sample(model, starting_str='The island'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities before scaling:         [0.10650698 0.10650698 0.78698605]\n",
      "Probabilities after scaling with 0.5: [0.21194156 0.21194156 0.57611686]\n",
      "Probabilities after scaling with 0.1: [0.3104238  0.3104238  0.37915248]\n"
     ]
    }
   ],
   "source": [
    "logits = torch.tensor([[1.0, 1.0, 3.0]])\n",
    "\n",
    "print('Probabilities before scaling:        ', nn.functional.softmax(logits, dim=1).numpy()[0])\n",
    "\n",
    "print('Probabilities after scaling with 0.5:', nn.functional.softmax(0.5*logits, dim=1).numpy()[0])\n",
    "\n",
    "print('Probabilities after scaling with 0.1:', nn.functional.softmax(0.1*logits, dim=1).numpy()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The island had been presented to the wood, which seemed to come to the water-spout of the Pacific. It was an island in the corral, and sandy must reach the last words were steamer which they had a solid in the table of the southern\n",
      "specimen, they were driven to the 25th of August, the sailor had showed this was in the most impresising of a solid thirty to the sand, and the point of the island, which was struggled without any attention of some transformation.\n",
      "\n",
      "“This was now that it would be said, the last \n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1)\n",
    "print(sample(model, starting_str='The island', \n",
    "             scale_factor=2.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the model (state dictionary)\n",
    "#saves the model's learnable parameters (weights and biases)\n",
    "model_state_dict = model.state_dict()\n",
    "torch.save(model_state_dict, \"20240226_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the entire model\n",
    "model.eval()\n",
    "torch.save(model, \"entire_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the model\n",
    "#torch.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The monkeys from the boat appeared to be descended to the shore,\n",
      "and when the sailor thought the most importance of the corral, was completely reporter.\n",
      "\n",
      "“The ‘Nautilus,’ found them. It was a substance of\n",
      "a word than the part of the subterranean fire of the stern to mark and a high continued in the corral.\n",
      "\n",
      "In the mouth, the passengers, and as the bottom of the same time to the distance of a week the incidents of the surface of the shore, and as if\n",
      "the hollowed of the sea--well, and the position of the air in t\n"
     ]
    }
   ],
   "source": [
    "#torch.manual_seed(1)\n",
    "print(sample(model, starting_str='The monkeys from', scale_factor=2.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The monkeys from the summit of the horizon was for the document was at least to far as if\n",
      "we shall stand for the sudden arrived at the sandy complete and a word the colonists of that time to the sand, and the sailor and Herbert, and Neb examined the reporter, “and now that the ‘Duncan’t was not a good and descending to the works,” replied the reporter. “I will ascend the opening is an\n",
      "inhabited words in the same time put to the surface of the point of the southern side\n",
      "of the lake and some power of the mountain\n"
     ]
    }
   ],
   "source": [
    "print(sample(model, starting_str='The monkeys from', scale_factor=2.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The monkeys from Claw Capehic acid of\n",
      "their specimen, and other part of the opening, and you help to escape the lake appeared to dwell\n",
      "towards it up in the hours.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Hhanchieft and the settlers disputed through frightful tonds. However, the water, which beds had chose winding of, that is to say, that\n",
      "doubtless, so as to begin as in widters, in a immediate time passed.\n",
      "\n",
      "Pencroft Breaks, scrently ran was smoken.\n",
      "Cyrus Harding appeared as if, to reply to put this famid river. Between the rock.\n",
      "How many on the s\n"
     ]
    }
   ],
   "source": [
    "print(sample(model, starting_str='The monkeys from', scale_factor=1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The monkeys from the mouth of the colonists would be finished, and as the engineer thought it was an infaction to the entrance of a sharp course at the corral was all the sailor and Neb and Herbert was there and the sailor, and Herbert, and the engineer were about to say, the colonists would have been fixed in the corral. The engineer and Neb had disappeared to be a substance to the sand, which would be the day where the plateau of the same time the one would be the balloon, in the same time to the sun. It was \n"
     ]
    }
   ],
   "source": [
    "print(sample(model, starting_str='The monkeys from', scale_factor=2.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One day the sailor was said, and the colonists had come as if the wood for the sand was still a long time to the corral. The sailor was then said to the same time to the same time as the case to the horizon of the summit of the wood. It was an\n",
      "exploration of the southern coast. It was so strong to the same time as the colonists were reached the shore, and as the colonists were allowed to the sailor, “if it is so as to be a spot where the wood of the coast of the plateau of the sand with a ship in the sand,\n"
     ]
    }
   ],
   "source": [
    "print(sample(model, starting_str='One day the', scale_factor=3.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Raschka-book",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
